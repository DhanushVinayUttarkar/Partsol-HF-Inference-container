{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c82fe49",
   "metadata": {},
   "source": [
    "# Partsol Inference Container â€“ Demo Notebook\n",
    "This notebook sends POST requests to the running container (via NGINX on port 8080) and prints responses.\n",
    "**Start the containers first** with `docker compose up --build` in the project root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41817b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "\n",
    "BASE = \"http://localhost:8080\"\n",
    "print(\"Target:\", BASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c352cb",
   "metadata": {},
   "source": [
    "## 1) Sentiment analysis\n",
    "Uses the default model `distilbert-base-uncased-finetuned-sst-2-english`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a528723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"task\": \"text-classification\",\n",
    "    \"inputs\": \"I love how easy it is to use this API!\",\n",
    "    # \"model_id\": \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "}\n",
    "r = requests.post(f\"{BASE}/api/infer\", json=payload, timeout=120)\n",
    "print(r.status_code)\n",
    "print(json.dumps(r.json(), indent=2)[:2000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e09712",
   "metadata": {},
   "source": [
    "## 2) Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002beda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"task\": \"text-generation\",\n",
    "    \"inputs\": \"In a distant future, AI systems will\",\n",
    "    \"parameters\": {\"max_new_tokens\": 20}\n",
    "}\n",
    "r = requests.post(f\"{BASE}/api/infer\", json=payload, timeout=180)\n",
    "print(r.status_code)\n",
    "print(json.dumps(r.json(), indent=2)[:2000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897dd21c",
   "metadata": {},
   "source": [
    "## 3) Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785eee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"task\": \"question-answering\",\n",
    "    \"inputs\": {\n",
    "        \"question\": \"Where do I send POST requests?\",\n",
    "        \"context\": \"Start the docker-compose stack. The API is reachable at http://localhost:8080/api/infer.\"\n",
    "    }\n",
    "}\n",
    "r = requests.post(f\"{BASE}/api/infer\", json=payload, timeout=120)\n",
    "print(r.status_code)\n",
    "print(json.dumps(r.json(), indent=2)[:2000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d763cc",
   "metadata": {},
   "source": [
    "## 4) Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e790aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a path to a local image file for a quick test\n",
    "image_path = None\n",
    "\n",
    "if image_path:\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        files = {\"file\": f}\n",
    "        # Optional model: (\"model_id\", (None, \"google/vit-base-patch16-224\"))\n",
    "        r = requests.post(f\"{BASE}/api/infer-image\", files=files, timeout=180)\n",
    "        print(r.status_code)\n",
    "        print(json.dumps(r.json(), indent=2)[:2000])\n",
    "else:\n",
    "    print(\"Missing image_path to test image-classification.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
